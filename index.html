---
layout: default
---

<body>
    <header class="page-header" role="banner">
      <a href="https://arxiv.org/abs/2408.16546" class="btn">arXiv paper</a>
    </header>

    <main id="content" class="main-content" role="main">
      <h1 id="sub-title">A Compact Model for Real-Time Multi-Instrument Sound Morphing</h1>  
      <h2 id="sub-sub-title">Demo page and audio examples</h2>

<font size="5"> Anonymous Authors </font>
        
<h2 id="abstract">Abstract</h2>

<p>Recent advances in transformer-and diffusion-based deep-generative models have significantly impacted the field of music and audio synthesis.
  However, controllable and real-time interactive models, such as those used for timbre transfer in music production,
  remain largely dominated by auto-encoders and generative adversarial networks.
  In pursuit of efficient and flexible timbre morphing and multi-instrument timbre transfer, we propose a simplified modeling approach,
  utilizing an upsampled two-dimensional timbre space in conjunction with engineered and instrument-dependent, excitation signals.
  Our model enables any-to-many timbre transfer with precise control over timbre, pitch, and loudness, while also allowing for seamless interpolation between instruments,
  eliminating the need for separate model training. We achieve performance comparable to specialized models, while supporting 44.1 kHz generation,
  making it highly relevant for the broader creative music community.</p>

<p></p>
